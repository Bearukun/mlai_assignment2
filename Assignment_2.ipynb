{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Data exploration\n",
    "Your first task is to download and explore the data. What features are there?\n",
    "How are they related?\n",
    "Hand two lines that describes\n",
    "* what a frequency is\n",
    "* what the median frequency means\n",
    "* what the output label is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('voice.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.132786</td>\n",
       "      <td>0.079557</td>\n",
       "      <td>0.119090</td>\n",
       "      <td>0.067958</td>\n",
       "      <td>0.209592</td>\n",
       "      <td>0.141634</td>\n",
       "      <td>1.932562</td>\n",
       "      <td>8.308895</td>\n",
       "      <td>0.963181</td>\n",
       "      <td>0.738307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132786</td>\n",
       "      <td>0.110132</td>\n",
       "      <td>0.017112</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.298222</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.726562</td>\n",
       "      <td>2.718750</td>\n",
       "      <td>0.125160</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.150762</td>\n",
       "      <td>0.074463</td>\n",
       "      <td>0.160106</td>\n",
       "      <td>0.092899</td>\n",
       "      <td>0.205718</td>\n",
       "      <td>0.112819</td>\n",
       "      <td>1.530643</td>\n",
       "      <td>5.987498</td>\n",
       "      <td>0.967573</td>\n",
       "      <td>0.762638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150762</td>\n",
       "      <td>0.105945</td>\n",
       "      <td>0.026230</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.479620</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.312500</td>\n",
       "      <td>5.304688</td>\n",
       "      <td>0.123992</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.160514</td>\n",
       "      <td>0.076767</td>\n",
       "      <td>0.144337</td>\n",
       "      <td>0.110532</td>\n",
       "      <td>0.231962</td>\n",
       "      <td>0.121430</td>\n",
       "      <td>1.397156</td>\n",
       "      <td>4.766611</td>\n",
       "      <td>0.959255</td>\n",
       "      <td>0.719858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160514</td>\n",
       "      <td>0.093052</td>\n",
       "      <td>0.017758</td>\n",
       "      <td>0.144144</td>\n",
       "      <td>0.301339</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.283937</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.142239</td>\n",
       "      <td>0.078018</td>\n",
       "      <td>0.138587</td>\n",
       "      <td>0.088206</td>\n",
       "      <td>0.208587</td>\n",
       "      <td>0.120381</td>\n",
       "      <td>1.099746</td>\n",
       "      <td>4.070284</td>\n",
       "      <td>0.970723</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142239</td>\n",
       "      <td>0.096729</td>\n",
       "      <td>0.017957</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.336476</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.164062</td>\n",
       "      <td>2.156250</td>\n",
       "      <td>0.148272</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.134329</td>\n",
       "      <td>0.080350</td>\n",
       "      <td>0.121451</td>\n",
       "      <td>0.075580</td>\n",
       "      <td>0.201957</td>\n",
       "      <td>0.126377</td>\n",
       "      <td>1.190368</td>\n",
       "      <td>4.787310</td>\n",
       "      <td>0.975246</td>\n",
       "      <td>0.804505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134329</td>\n",
       "      <td>0.105881</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.340365</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>4.695312</td>\n",
       "      <td>4.679688</td>\n",
       "      <td>0.089920</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.157021</td>\n",
       "      <td>0.071943</td>\n",
       "      <td>0.168160</td>\n",
       "      <td>0.101430</td>\n",
       "      <td>0.216740</td>\n",
       "      <td>0.115310</td>\n",
       "      <td>0.979442</td>\n",
       "      <td>3.974223</td>\n",
       "      <td>0.965249</td>\n",
       "      <td>0.733693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157021</td>\n",
       "      <td>0.088894</td>\n",
       "      <td>0.022069</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.460227</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.812500</td>\n",
       "      <td>2.804688</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.138551</td>\n",
       "      <td>0.077054</td>\n",
       "      <td>0.127527</td>\n",
       "      <td>0.087314</td>\n",
       "      <td>0.202739</td>\n",
       "      <td>0.115426</td>\n",
       "      <td>1.626770</td>\n",
       "      <td>6.291365</td>\n",
       "      <td>0.966004</td>\n",
       "      <td>0.752042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138551</td>\n",
       "      <td>0.104199</td>\n",
       "      <td>0.019139</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.246094</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.718750</td>\n",
       "      <td>2.710938</td>\n",
       "      <td>0.132351</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.137343</td>\n",
       "      <td>0.080877</td>\n",
       "      <td>0.124263</td>\n",
       "      <td>0.083145</td>\n",
       "      <td>0.209227</td>\n",
       "      <td>0.126082</td>\n",
       "      <td>1.378728</td>\n",
       "      <td>5.008952</td>\n",
       "      <td>0.963514</td>\n",
       "      <td>0.736150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137343</td>\n",
       "      <td>0.092644</td>\n",
       "      <td>0.016789</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.481671</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>5.015625</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.181225</td>\n",
       "      <td>0.060042</td>\n",
       "      <td>0.190953</td>\n",
       "      <td>0.128839</td>\n",
       "      <td>0.229532</td>\n",
       "      <td>0.100693</td>\n",
       "      <td>1.369430</td>\n",
       "      <td>5.475600</td>\n",
       "      <td>0.937446</td>\n",
       "      <td>0.537080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181225</td>\n",
       "      <td>0.131504</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>1.277114</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.804688</td>\n",
       "      <td>2.796875</td>\n",
       "      <td>0.416550</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.183115</td>\n",
       "      <td>0.066982</td>\n",
       "      <td>0.191233</td>\n",
       "      <td>0.129149</td>\n",
       "      <td>0.240152</td>\n",
       "      <td>0.111004</td>\n",
       "      <td>3.568104</td>\n",
       "      <td>35.384748</td>\n",
       "      <td>0.940333</td>\n",
       "      <td>0.571394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183115</td>\n",
       "      <td>0.102799</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>1.245739</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>6.742188</td>\n",
       "      <td>6.539062</td>\n",
       "      <td>0.139332</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.174272</td>\n",
       "      <td>0.069411</td>\n",
       "      <td>0.190874</td>\n",
       "      <td>0.115602</td>\n",
       "      <td>0.228279</td>\n",
       "      <td>0.112677</td>\n",
       "      <td>4.485038</td>\n",
       "      <td>61.764908</td>\n",
       "      <td>0.950972</td>\n",
       "      <td>0.635199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174272</td>\n",
       "      <td>0.102046</td>\n",
       "      <td>0.018328</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>1.621299</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.992188</td>\n",
       "      <td>0.209311</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.190846</td>\n",
       "      <td>0.065790</td>\n",
       "      <td>0.207951</td>\n",
       "      <td>0.132280</td>\n",
       "      <td>0.244357</td>\n",
       "      <td>0.112076</td>\n",
       "      <td>1.562304</td>\n",
       "      <td>7.834350</td>\n",
       "      <td>0.938546</td>\n",
       "      <td>0.538810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190846</td>\n",
       "      <td>0.113323</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>1.434115</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>6.320312</td>\n",
       "      <td>6.312500</td>\n",
       "      <td>0.254780</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.171247</td>\n",
       "      <td>0.074872</td>\n",
       "      <td>0.152807</td>\n",
       "      <td>0.122391</td>\n",
       "      <td>0.243617</td>\n",
       "      <td>0.121227</td>\n",
       "      <td>3.207170</td>\n",
       "      <td>25.765565</td>\n",
       "      <td>0.936954</td>\n",
       "      <td>0.586420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171247</td>\n",
       "      <td>0.079718</td>\n",
       "      <td>0.015671</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.106279</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.138355</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.168346</td>\n",
       "      <td>0.074121</td>\n",
       "      <td>0.145618</td>\n",
       "      <td>0.115756</td>\n",
       "      <td>0.239824</td>\n",
       "      <td>0.124068</td>\n",
       "      <td>2.704335</td>\n",
       "      <td>18.484703</td>\n",
       "      <td>0.934523</td>\n",
       "      <td>0.559742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168346</td>\n",
       "      <td>0.083484</td>\n",
       "      <td>0.015717</td>\n",
       "      <td>0.231884</td>\n",
       "      <td>0.146563</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>3.117188</td>\n",
       "      <td>0.059537</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.173631</td>\n",
       "      <td>0.073352</td>\n",
       "      <td>0.153569</td>\n",
       "      <td>0.123680</td>\n",
       "      <td>0.244234</td>\n",
       "      <td>0.120554</td>\n",
       "      <td>2.804975</td>\n",
       "      <td>20.857543</td>\n",
       "      <td>0.930917</td>\n",
       "      <td>0.518269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173631</td>\n",
       "      <td>0.090130</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.193044</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.820312</td>\n",
       "      <td>2.812500</td>\n",
       "      <td>0.068124</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.172754</td>\n",
       "      <td>0.076903</td>\n",
       "      <td>0.177736</td>\n",
       "      <td>0.120070</td>\n",
       "      <td>0.245368</td>\n",
       "      <td>0.125298</td>\n",
       "      <td>2.967765</td>\n",
       "      <td>20.078115</td>\n",
       "      <td>0.925539</td>\n",
       "      <td>0.523081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172754</td>\n",
       "      <td>0.093574</td>\n",
       "      <td>0.015764</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.235877</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.710938</td>\n",
       "      <td>0.235069</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.181015</td>\n",
       "      <td>0.074369</td>\n",
       "      <td>0.169299</td>\n",
       "      <td>0.128673</td>\n",
       "      <td>0.254175</td>\n",
       "      <td>0.125502</td>\n",
       "      <td>2.587325</td>\n",
       "      <td>12.281432</td>\n",
       "      <td>0.915284</td>\n",
       "      <td>0.475317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181015</td>\n",
       "      <td>0.098643</td>\n",
       "      <td>0.016145</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>3.695312</td>\n",
       "      <td>3.687500</td>\n",
       "      <td>0.059940</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.163536</td>\n",
       "      <td>0.072449</td>\n",
       "      <td>0.145543</td>\n",
       "      <td>0.113930</td>\n",
       "      <td>0.227449</td>\n",
       "      <td>0.113519</td>\n",
       "      <td>3.587650</td>\n",
       "      <td>28.653781</td>\n",
       "      <td>0.927015</td>\n",
       "      <td>0.542422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163536</td>\n",
       "      <td>0.062542</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.197531</td>\n",
       "      <td>0.059622</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.445312</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.091699</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.075105</td>\n",
       "      <td>0.146053</td>\n",
       "      <td>0.123989</td>\n",
       "      <td>0.250126</td>\n",
       "      <td>0.126137</td>\n",
       "      <td>2.816793</td>\n",
       "      <td>13.764582</td>\n",
       "      <td>0.913832</td>\n",
       "      <td>0.487966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.077698</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.192771</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.161791</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.160422</td>\n",
       "      <td>0.076615</td>\n",
       "      <td>0.144824</td>\n",
       "      <td>0.120924</td>\n",
       "      <td>0.237244</td>\n",
       "      <td>0.116319</td>\n",
       "      <td>6.253208</td>\n",
       "      <td>85.491926</td>\n",
       "      <td>0.933030</td>\n",
       "      <td>0.567424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160422</td>\n",
       "      <td>0.098944</td>\n",
       "      <td>0.016097</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.206756</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>3.953125</td>\n",
       "      <td>3.945312</td>\n",
       "      <td>0.073890</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.164700</td>\n",
       "      <td>0.075362</td>\n",
       "      <td>0.147018</td>\n",
       "      <td>0.118698</td>\n",
       "      <td>0.240475</td>\n",
       "      <td>0.121777</td>\n",
       "      <td>4.208608</td>\n",
       "      <td>43.681885</td>\n",
       "      <td>0.940669</td>\n",
       "      <td>0.604020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164700</td>\n",
       "      <td>0.082963</td>\n",
       "      <td>0.015640</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.143353</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>1.062500</td>\n",
       "      <td>1.054688</td>\n",
       "      <td>0.125926</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.169579</td>\n",
       "      <td>0.075635</td>\n",
       "      <td>0.186468</td>\n",
       "      <td>0.116706</td>\n",
       "      <td>0.238549</td>\n",
       "      <td>0.121843</td>\n",
       "      <td>4.269923</td>\n",
       "      <td>45.895248</td>\n",
       "      <td>0.929498</td>\n",
       "      <td>0.543709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169579</td>\n",
       "      <td>0.082451</td>\n",
       "      <td>0.016211</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.148438</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>3.609375</td>\n",
       "      <td>3.601562</td>\n",
       "      <td>0.050841</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.169021</td>\n",
       "      <td>0.071778</td>\n",
       "      <td>0.143168</td>\n",
       "      <td>0.125801</td>\n",
       "      <td>0.248315</td>\n",
       "      <td>0.122515</td>\n",
       "      <td>3.079273</td>\n",
       "      <td>14.340299</td>\n",
       "      <td>0.902275</td>\n",
       "      <td>0.477746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169021</td>\n",
       "      <td>0.130598</td>\n",
       "      <td>0.015842</td>\n",
       "      <td>0.225352</td>\n",
       "      <td>0.335313</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.710938</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.397354</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.072841</td>\n",
       "      <td>0.141739</td>\n",
       "      <td>0.122174</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.117826</td>\n",
       "      <td>2.192126</td>\n",
       "      <td>8.152410</td>\n",
       "      <td>0.913763</td>\n",
       "      <td>0.539479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167340</td>\n",
       "      <td>0.120052</td>\n",
       "      <td>0.016244</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.298678</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.679688</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.384778</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.180528</td>\n",
       "      <td>0.070867</td>\n",
       "      <td>0.142385</td>\n",
       "      <td>0.129541</td>\n",
       "      <td>0.252477</td>\n",
       "      <td>0.122936</td>\n",
       "      <td>2.799969</td>\n",
       "      <td>12.190361</td>\n",
       "      <td>0.853115</td>\n",
       "      <td>0.313426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180528</td>\n",
       "      <td>0.126607</td>\n",
       "      <td>0.017039</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.234863</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.329241</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>0.114477</td>\n",
       "      <td>0.081973</td>\n",
       "      <td>0.090199</td>\n",
       "      <td>0.041095</td>\n",
       "      <td>0.199900</td>\n",
       "      <td>0.158806</td>\n",
       "      <td>1.103680</td>\n",
       "      <td>3.759184</td>\n",
       "      <td>0.954130</td>\n",
       "      <td>0.689347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114477</td>\n",
       "      <td>0.189394</td>\n",
       "      <td>0.016343</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.566840</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.273438</td>\n",
       "      <td>4.265625</td>\n",
       "      <td>0.183258</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>0.112769</td>\n",
       "      <td>0.074424</td>\n",
       "      <td>0.094248</td>\n",
       "      <td>0.049183</td>\n",
       "      <td>0.183235</td>\n",
       "      <td>0.134052</td>\n",
       "      <td>0.945953</td>\n",
       "      <td>3.290904</td>\n",
       "      <td>0.965719</td>\n",
       "      <td>0.742464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112769</td>\n",
       "      <td>0.169836</td>\n",
       "      <td>0.017917</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.877604</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.937500</td>\n",
       "      <td>4.929688</td>\n",
       "      <td>0.171708</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>0.126439</td>\n",
       "      <td>0.079412</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>0.046889</td>\n",
       "      <td>0.198993</td>\n",
       "      <td>0.152103</td>\n",
       "      <td>1.452173</td>\n",
       "      <td>5.582106</td>\n",
       "      <td>0.971946</td>\n",
       "      <td>0.790175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126439</td>\n",
       "      <td>0.179613</td>\n",
       "      <td>0.029575</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.614110</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.914062</td>\n",
       "      <td>4.906250</td>\n",
       "      <td>0.090045</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>0.117350</td>\n",
       "      <td>0.090035</td>\n",
       "      <td>0.109478</td>\n",
       "      <td>0.024017</td>\n",
       "      <td>0.203946</td>\n",
       "      <td>0.179929</td>\n",
       "      <td>2.610623</td>\n",
       "      <td>12.442898</td>\n",
       "      <td>0.953624</td>\n",
       "      <td>0.701434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117350</td>\n",
       "      <td>0.178040</td>\n",
       "      <td>0.016512</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.188721</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>0.277759</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>0.104793</td>\n",
       "      <td>0.085201</td>\n",
       "      <td>0.077886</td>\n",
       "      <td>0.028388</td>\n",
       "      <td>0.186101</td>\n",
       "      <td>0.157712</td>\n",
       "      <td>2.419127</td>\n",
       "      <td>11.281968</td>\n",
       "      <td>0.956977</td>\n",
       "      <td>0.718462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104793</td>\n",
       "      <td>0.183565</td>\n",
       "      <td>0.016444</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.297953</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.851562</td>\n",
       "      <td>0.370904</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143</th>\n",
       "      <td>0.127633</td>\n",
       "      <td>0.084931</td>\n",
       "      <td>0.158892</td>\n",
       "      <td>0.034531</td>\n",
       "      <td>0.201430</td>\n",
       "      <td>0.166899</td>\n",
       "      <td>1.591174</td>\n",
       "      <td>5.347645</td>\n",
       "      <td>0.949757</td>\n",
       "      <td>0.671247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127633</td>\n",
       "      <td>0.178363</td>\n",
       "      <td>0.058182</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.634014</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>5.031250</td>\n",
       "      <td>5.015625</td>\n",
       "      <td>0.121246</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>0.091250</td>\n",
       "      <td>0.086956</td>\n",
       "      <td>0.048191</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>0.179043</td>\n",
       "      <td>0.163851</td>\n",
       "      <td>3.089787</td>\n",
       "      <td>12.857558</td>\n",
       "      <td>0.930715</td>\n",
       "      <td>0.622816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091250</td>\n",
       "      <td>0.170893</td>\n",
       "      <td>0.016178</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.767314</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.289062</td>\n",
       "      <td>5.281250</td>\n",
       "      <td>0.187912</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>0.082404</td>\n",
       "      <td>0.085136</td>\n",
       "      <td>0.035114</td>\n",
       "      <td>0.016920</td>\n",
       "      <td>0.152827</td>\n",
       "      <td>0.135906</td>\n",
       "      <td>2.570944</td>\n",
       "      <td>9.179264</td>\n",
       "      <td>0.921649</td>\n",
       "      <td>0.576089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082404</td>\n",
       "      <td>0.183387</td>\n",
       "      <td>0.034043</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.328962</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>0.445053</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3146</th>\n",
       "      <td>0.124695</td>\n",
       "      <td>0.080989</td>\n",
       "      <td>0.131882</td>\n",
       "      <td>0.042033</td>\n",
       "      <td>0.197268</td>\n",
       "      <td>0.155234</td>\n",
       "      <td>1.970756</td>\n",
       "      <td>8.000504</td>\n",
       "      <td>0.958531</td>\n",
       "      <td>0.721682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124695</td>\n",
       "      <td>0.182513</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.238806</td>\n",
       "      <td>0.293527</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.851562</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.396091</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3147</th>\n",
       "      <td>0.131566</td>\n",
       "      <td>0.084354</td>\n",
       "      <td>0.131889</td>\n",
       "      <td>0.053093</td>\n",
       "      <td>0.196147</td>\n",
       "      <td>0.143055</td>\n",
       "      <td>2.243370</td>\n",
       "      <td>11.544740</td>\n",
       "      <td>0.968324</td>\n",
       "      <td>0.784108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131566</td>\n",
       "      <td>0.191163</td>\n",
       "      <td>0.029144</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.214725</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.351645</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3148</th>\n",
       "      <td>0.108888</td>\n",
       "      <td>0.092021</td>\n",
       "      <td>0.070063</td>\n",
       "      <td>0.022520</td>\n",
       "      <td>0.201180</td>\n",
       "      <td>0.178660</td>\n",
       "      <td>2.235435</td>\n",
       "      <td>8.528681</td>\n",
       "      <td>0.947621</td>\n",
       "      <td>0.679795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108888</td>\n",
       "      <td>0.160473</td>\n",
       "      <td>0.019512</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.497721</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.945312</td>\n",
       "      <td>2.937500</td>\n",
       "      <td>0.236240</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3149</th>\n",
       "      <td>0.090445</td>\n",
       "      <td>0.079045</td>\n",
       "      <td>0.059358</td>\n",
       "      <td>0.020893</td>\n",
       "      <td>0.167727</td>\n",
       "      <td>0.146834</td>\n",
       "      <td>2.187161</td>\n",
       "      <td>8.221164</td>\n",
       "      <td>0.942404</td>\n",
       "      <td>0.628992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090445</td>\n",
       "      <td>0.182431</td>\n",
       "      <td>0.026622</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.735453</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.531250</td>\n",
       "      <td>5.523438</td>\n",
       "      <td>0.170489</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3150</th>\n",
       "      <td>0.137507</td>\n",
       "      <td>0.091521</td>\n",
       "      <td>0.161298</td>\n",
       "      <td>0.043547</td>\n",
       "      <td>0.221260</td>\n",
       "      <td>0.177713</td>\n",
       "      <td>1.119608</td>\n",
       "      <td>4.185207</td>\n",
       "      <td>0.967706</td>\n",
       "      <td>0.739008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137507</td>\n",
       "      <td>0.190093</td>\n",
       "      <td>0.019116</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.354367</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>3.117188</td>\n",
       "      <td>3.109375</td>\n",
       "      <td>0.096069</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3151</th>\n",
       "      <td>0.113148</td>\n",
       "      <td>0.090335</td>\n",
       "      <td>0.084335</td>\n",
       "      <td>0.026622</td>\n",
       "      <td>0.198830</td>\n",
       "      <td>0.172207</td>\n",
       "      <td>2.258273</td>\n",
       "      <td>9.579337</td>\n",
       "      <td>0.957433</td>\n",
       "      <td>0.717683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113148</td>\n",
       "      <td>0.187444</td>\n",
       "      <td>0.023495</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.622489</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.898438</td>\n",
       "      <td>4.890625</td>\n",
       "      <td>0.128717</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3152</th>\n",
       "      <td>0.149731</td>\n",
       "      <td>0.082852</td>\n",
       "      <td>0.180932</td>\n",
       "      <td>0.060212</td>\n",
       "      <td>0.219788</td>\n",
       "      <td>0.159576</td>\n",
       "      <td>1.240037</td>\n",
       "      <td>4.019385</td>\n",
       "      <td>0.949787</td>\n",
       "      <td>0.652936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149731</td>\n",
       "      <td>0.183974</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>1.361213</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>6.031250</td>\n",
       "      <td>5.828125</td>\n",
       "      <td>0.365700</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3153</th>\n",
       "      <td>0.189614</td>\n",
       "      <td>0.035933</td>\n",
       "      <td>0.194116</td>\n",
       "      <td>0.168434</td>\n",
       "      <td>0.205289</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>2.724415</td>\n",
       "      <td>10.986864</td>\n",
       "      <td>0.871215</td>\n",
       "      <td>0.236684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189614</td>\n",
       "      <td>0.163059</td>\n",
       "      <td>0.029685</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>1.370192</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.835938</td>\n",
       "      <td>0.235948</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3154</th>\n",
       "      <td>0.200097</td>\n",
       "      <td>0.045533</td>\n",
       "      <td>0.203796</td>\n",
       "      <td>0.176581</td>\n",
       "      <td>0.232133</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>1.160197</td>\n",
       "      <td>3.733815</td>\n",
       "      <td>0.919607</td>\n",
       "      <td>0.357144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200097</td>\n",
       "      <td>0.168531</td>\n",
       "      <td>0.063241</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.148438</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.851562</td>\n",
       "      <td>0.092208</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155</th>\n",
       "      <td>0.178573</td>\n",
       "      <td>0.046679</td>\n",
       "      <td>0.164388</td>\n",
       "      <td>0.149309</td>\n",
       "      <td>0.204601</td>\n",
       "      <td>0.055293</td>\n",
       "      <td>3.066668</td>\n",
       "      <td>15.684088</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.321169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178573</td>\n",
       "      <td>0.155380</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.637921</td>\n",
       "      <td>0.148438</td>\n",
       "      <td>6.148438</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.101291</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3156</th>\n",
       "      <td>0.201806</td>\n",
       "      <td>0.036057</td>\n",
       "      <td>0.201622</td>\n",
       "      <td>0.178165</td>\n",
       "      <td>0.227872</td>\n",
       "      <td>0.049707</td>\n",
       "      <td>1.585353</td>\n",
       "      <td>4.945634</td>\n",
       "      <td>0.884731</td>\n",
       "      <td>0.227903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201806</td>\n",
       "      <td>0.191704</td>\n",
       "      <td>0.032720</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.921875</td>\n",
       "      <td>5.914062</td>\n",
       "      <td>0.124383</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3157</th>\n",
       "      <td>0.203627</td>\n",
       "      <td>0.041529</td>\n",
       "      <td>0.204104</td>\n",
       "      <td>0.175661</td>\n",
       "      <td>0.239122</td>\n",
       "      <td>0.063461</td>\n",
       "      <td>1.462972</td>\n",
       "      <td>4.790370</td>\n",
       "      <td>0.903458</td>\n",
       "      <td>0.246953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203627</td>\n",
       "      <td>0.146783</td>\n",
       "      <td>0.020566</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.875558</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>6.898438</td>\n",
       "      <td>6.726562</td>\n",
       "      <td>0.145534</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3158</th>\n",
       "      <td>0.183667</td>\n",
       "      <td>0.040607</td>\n",
       "      <td>0.182534</td>\n",
       "      <td>0.156480</td>\n",
       "      <td>0.207646</td>\n",
       "      <td>0.051166</td>\n",
       "      <td>2.054138</td>\n",
       "      <td>7.483019</td>\n",
       "      <td>0.898138</td>\n",
       "      <td>0.313925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183667</td>\n",
       "      <td>0.149237</td>\n",
       "      <td>0.018648</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.550312</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>3.421875</td>\n",
       "      <td>3.414062</td>\n",
       "      <td>0.166503</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159</th>\n",
       "      <td>0.168794</td>\n",
       "      <td>0.085842</td>\n",
       "      <td>0.188980</td>\n",
       "      <td>0.095558</td>\n",
       "      <td>0.240229</td>\n",
       "      <td>0.144671</td>\n",
       "      <td>1.462248</td>\n",
       "      <td>5.077956</td>\n",
       "      <td>0.956201</td>\n",
       "      <td>0.706861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168794</td>\n",
       "      <td>0.182863</td>\n",
       "      <td>0.020699</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.988281</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.882812</td>\n",
       "      <td>5.875000</td>\n",
       "      <td>0.268617</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3160</th>\n",
       "      <td>0.151771</td>\n",
       "      <td>0.089147</td>\n",
       "      <td>0.185970</td>\n",
       "      <td>0.058159</td>\n",
       "      <td>0.230199</td>\n",
       "      <td>0.172040</td>\n",
       "      <td>1.227710</td>\n",
       "      <td>4.304354</td>\n",
       "      <td>0.962045</td>\n",
       "      <td>0.744590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151771</td>\n",
       "      <td>0.201600</td>\n",
       "      <td>0.023426</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.766741</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.007812</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.192220</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3161</th>\n",
       "      <td>0.170656</td>\n",
       "      <td>0.081237</td>\n",
       "      <td>0.184277</td>\n",
       "      <td>0.113012</td>\n",
       "      <td>0.239096</td>\n",
       "      <td>0.126084</td>\n",
       "      <td>1.378256</td>\n",
       "      <td>5.431663</td>\n",
       "      <td>0.950750</td>\n",
       "      <td>0.658558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170656</td>\n",
       "      <td>0.198475</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.414062</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.726562</td>\n",
       "      <td>0.336918</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3162</th>\n",
       "      <td>0.146023</td>\n",
       "      <td>0.092525</td>\n",
       "      <td>0.183434</td>\n",
       "      <td>0.041747</td>\n",
       "      <td>0.224337</td>\n",
       "      <td>0.182590</td>\n",
       "      <td>1.384981</td>\n",
       "      <td>5.118927</td>\n",
       "      <td>0.948999</td>\n",
       "      <td>0.659825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146023</td>\n",
       "      <td>0.195640</td>\n",
       "      <td>0.039506</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.533854</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.992188</td>\n",
       "      <td>2.984375</td>\n",
       "      <td>0.258924</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>0.131884</td>\n",
       "      <td>0.084734</td>\n",
       "      <td>0.153707</td>\n",
       "      <td>0.049285</td>\n",
       "      <td>0.201144</td>\n",
       "      <td>0.151859</td>\n",
       "      <td>1.762129</td>\n",
       "      <td>6.630383</td>\n",
       "      <td>0.962934</td>\n",
       "      <td>0.763182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131884</td>\n",
       "      <td>0.182790</td>\n",
       "      <td>0.083770</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.832899</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.210938</td>\n",
       "      <td>4.203125</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>0.116221</td>\n",
       "      <td>0.089221</td>\n",
       "      <td>0.076758</td>\n",
       "      <td>0.042718</td>\n",
       "      <td>0.204911</td>\n",
       "      <td>0.162193</td>\n",
       "      <td>0.693730</td>\n",
       "      <td>2.503954</td>\n",
       "      <td>0.960716</td>\n",
       "      <td>0.709570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116221</td>\n",
       "      <td>0.188980</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.909856</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>3.679688</td>\n",
       "      <td>3.640625</td>\n",
       "      <td>0.277897</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>0.142056</td>\n",
       "      <td>0.095798</td>\n",
       "      <td>0.183731</td>\n",
       "      <td>0.033424</td>\n",
       "      <td>0.224360</td>\n",
       "      <td>0.190936</td>\n",
       "      <td>1.876502</td>\n",
       "      <td>6.604509</td>\n",
       "      <td>0.946854</td>\n",
       "      <td>0.654196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142056</td>\n",
       "      <td>0.209918</td>\n",
       "      <td>0.039506</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.494271</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.937500</td>\n",
       "      <td>2.929688</td>\n",
       "      <td>0.194759</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>0.143659</td>\n",
       "      <td>0.090628</td>\n",
       "      <td>0.184976</td>\n",
       "      <td>0.043508</td>\n",
       "      <td>0.219943</td>\n",
       "      <td>0.176435</td>\n",
       "      <td>1.591065</td>\n",
       "      <td>5.388298</td>\n",
       "      <td>0.950436</td>\n",
       "      <td>0.675470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143659</td>\n",
       "      <td>0.172375</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.791360</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>3.593750</td>\n",
       "      <td>3.585938</td>\n",
       "      <td>0.311002</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.092884</td>\n",
       "      <td>0.183044</td>\n",
       "      <td>0.070072</td>\n",
       "      <td>0.250827</td>\n",
       "      <td>0.180756</td>\n",
       "      <td>1.705029</td>\n",
       "      <td>5.769115</td>\n",
       "      <td>0.938829</td>\n",
       "      <td>0.601529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.185607</td>\n",
       "      <td>0.062257</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.227022</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3168 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0     0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1     0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2     0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3     0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4     0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "5     0.132786  0.079557  0.119090  0.067958  0.209592  0.141634   1.932562   \n",
       "6     0.150762  0.074463  0.160106  0.092899  0.205718  0.112819   1.530643   \n",
       "7     0.160514  0.076767  0.144337  0.110532  0.231962  0.121430   1.397156   \n",
       "8     0.142239  0.078018  0.138587  0.088206  0.208587  0.120381   1.099746   \n",
       "9     0.134329  0.080350  0.121451  0.075580  0.201957  0.126377   1.190368   \n",
       "10    0.157021  0.071943  0.168160  0.101430  0.216740  0.115310   0.979442   \n",
       "11    0.138551  0.077054  0.127527  0.087314  0.202739  0.115426   1.626770   \n",
       "12    0.137343  0.080877  0.124263  0.083145  0.209227  0.126082   1.378728   \n",
       "13    0.181225  0.060042  0.190953  0.128839  0.229532  0.100693   1.369430   \n",
       "14    0.183115  0.066982  0.191233  0.129149  0.240152  0.111004   3.568104   \n",
       "15    0.174272  0.069411  0.190874  0.115602  0.228279  0.112677   4.485038   \n",
       "16    0.190846  0.065790  0.207951  0.132280  0.244357  0.112076   1.562304   \n",
       "17    0.171247  0.074872  0.152807  0.122391  0.243617  0.121227   3.207170   \n",
       "18    0.168346  0.074121  0.145618  0.115756  0.239824  0.124068   2.704335   \n",
       "19    0.173631  0.073352  0.153569  0.123680  0.244234  0.120554   2.804975   \n",
       "20    0.172754  0.076903  0.177736  0.120070  0.245368  0.125298   2.967765   \n",
       "21    0.181015  0.074369  0.169299  0.128673  0.254175  0.125502   2.587325   \n",
       "22    0.163536  0.072449  0.145543  0.113930  0.227449  0.113519   3.587650   \n",
       "23    0.170213  0.075105  0.146053  0.123989  0.250126  0.126137   2.816793   \n",
       "24    0.160422  0.076615  0.144824  0.120924  0.237244  0.116319   6.253208   \n",
       "25    0.164700  0.075362  0.147018  0.118698  0.240475  0.121777   4.208608   \n",
       "26    0.169579  0.075635  0.186468  0.116706  0.238549  0.121843   4.269923   \n",
       "27    0.169021  0.071778  0.143168  0.125801  0.248315  0.122515   3.079273   \n",
       "28    0.167340  0.072841  0.141739  0.122174  0.240000  0.117826   2.192126   \n",
       "29    0.180528  0.070867  0.142385  0.129541  0.252477  0.122936   2.799969   \n",
       "...        ...       ...       ...       ...       ...       ...        ...   \n",
       "3138  0.114477  0.081973  0.090199  0.041095  0.199900  0.158806   1.103680   \n",
       "3139  0.112769  0.074424  0.094248  0.049183  0.183235  0.134052   0.945953   \n",
       "3140  0.126439  0.079412  0.127325  0.046889  0.198993  0.152103   1.452173   \n",
       "3141  0.117350  0.090035  0.109478  0.024017  0.203946  0.179929   2.610623   \n",
       "3142  0.104793  0.085201  0.077886  0.028388  0.186101  0.157712   2.419127   \n",
       "3143  0.127633  0.084931  0.158892  0.034531  0.201430  0.166899   1.591174   \n",
       "3144  0.091250  0.086956  0.048191  0.015193  0.179043  0.163851   3.089787   \n",
       "3145  0.082404  0.085136  0.035114  0.016920  0.152827  0.135906   2.570944   \n",
       "3146  0.124695  0.080989  0.131882  0.042033  0.197268  0.155234   1.970756   \n",
       "3147  0.131566  0.084354  0.131889  0.053093  0.196147  0.143055   2.243370   \n",
       "3148  0.108888  0.092021  0.070063  0.022520  0.201180  0.178660   2.235435   \n",
       "3149  0.090445  0.079045  0.059358  0.020893  0.167727  0.146834   2.187161   \n",
       "3150  0.137507  0.091521  0.161298  0.043547  0.221260  0.177713   1.119608   \n",
       "3151  0.113148  0.090335  0.084335  0.026622  0.198830  0.172207   2.258273   \n",
       "3152  0.149731  0.082852  0.180932  0.060212  0.219788  0.159576   1.240037   \n",
       "3153  0.189614  0.035933  0.194116  0.168434  0.205289  0.036855   2.724415   \n",
       "3154  0.200097  0.045533  0.203796  0.176581  0.232133  0.055552   1.160197   \n",
       "3155  0.178573  0.046679  0.164388  0.149309  0.204601  0.055293   3.066668   \n",
       "3156  0.201806  0.036057  0.201622  0.178165  0.227872  0.049707   1.585353   \n",
       "3157  0.203627  0.041529  0.204104  0.175661  0.239122  0.063461   1.462972   \n",
       "3158  0.183667  0.040607  0.182534  0.156480  0.207646  0.051166   2.054138   \n",
       "3159  0.168794  0.085842  0.188980  0.095558  0.240229  0.144671   1.462248   \n",
       "3160  0.151771  0.089147  0.185970  0.058159  0.230199  0.172040   1.227710   \n",
       "3161  0.170656  0.081237  0.184277  0.113012  0.239096  0.126084   1.378256   \n",
       "3162  0.146023  0.092525  0.183434  0.041747  0.224337  0.182590   1.384981   \n",
       "3163  0.131884  0.084734  0.153707  0.049285  0.201144  0.151859   1.762129   \n",
       "3164  0.116221  0.089221  0.076758  0.042718  0.204911  0.162193   0.693730   \n",
       "3165  0.142056  0.095798  0.183731  0.033424  0.224360  0.190936   1.876502   \n",
       "3166  0.143659  0.090628  0.184976  0.043508  0.219943  0.176435   1.591065   \n",
       "3167  0.165509  0.092884  0.183044  0.070072  0.250827  0.180756   1.705029   \n",
       "\n",
       "             kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "0      274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
       "1      634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
       "2     1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
       "3        4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
       "4        4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
       "5        8.308895  0.963181  0.738307  ...  0.132786  0.110132  0.017112   \n",
       "6        5.987498  0.967573  0.762638  ...  0.150762  0.105945  0.026230   \n",
       "7        4.766611  0.959255  0.719858  ...  0.160514  0.093052  0.017758   \n",
       "8        4.070284  0.970723  0.770992  ...  0.142239  0.096729  0.017957   \n",
       "9        4.787310  0.975246  0.804505  ...  0.134329  0.105881  0.019300   \n",
       "10       3.974223  0.965249  0.733693  ...  0.157021  0.088894  0.022069   \n",
       "11       6.291365  0.966004  0.752042  ...  0.138551  0.104199  0.019139   \n",
       "12       5.008952  0.963514  0.736150  ...  0.137343  0.092644  0.016789   \n",
       "13       5.475600  0.937446  0.537080  ...  0.181225  0.131504  0.025000   \n",
       "14      35.384748  0.940333  0.571394  ...  0.183115  0.102799  0.020833   \n",
       "15      61.764908  0.950972  0.635199  ...  0.174272  0.102046  0.018328   \n",
       "16       7.834350  0.938546  0.538810  ...  0.190846  0.113323  0.017544   \n",
       "17      25.765565  0.936954  0.586420  ...  0.171247  0.079718  0.015671   \n",
       "18      18.484703  0.934523  0.559742  ...  0.168346  0.083484  0.015717   \n",
       "19      20.857543  0.930917  0.518269  ...  0.173631  0.090130  0.015702   \n",
       "20      20.078115  0.925539  0.523081  ...  0.172754  0.093574  0.015764   \n",
       "21      12.281432  0.915284  0.475317  ...  0.181015  0.098643  0.016145   \n",
       "22      28.653781  0.927015  0.542422  ...  0.163536  0.062542  0.015686   \n",
       "23      13.764582  0.913832  0.487966  ...  0.170213  0.077698  0.015702   \n",
       "24      85.491926  0.933030  0.567424  ...  0.160422  0.098944  0.016097   \n",
       "25      43.681885  0.940669  0.604020  ...  0.164700  0.082963  0.015640   \n",
       "26      45.895248  0.929498  0.543709  ...  0.169579  0.082451  0.016211   \n",
       "27      14.340299  0.902275  0.477746  ...  0.169021  0.130598  0.015842   \n",
       "28       8.152410  0.913763  0.539479  ...  0.167340  0.120052  0.016244   \n",
       "29      12.190361  0.853115  0.313426  ...  0.180528  0.126607  0.017039   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "3138     3.759184  0.954130  0.689347  ...  0.114477  0.189394  0.016343   \n",
       "3139     3.290904  0.965719  0.742464  ...  0.112769  0.169836  0.017917   \n",
       "3140     5.582106  0.971946  0.790175  ...  0.126439  0.179613  0.029575   \n",
       "3141    12.442898  0.953624  0.701434  ...  0.117350  0.178040  0.016512   \n",
       "3142    11.281968  0.956977  0.718462  ...  0.104793  0.183565  0.016444   \n",
       "3143     5.347645  0.949757  0.671247  ...  0.127633  0.178363  0.058182   \n",
       "3144    12.857558  0.930715  0.622816  ...  0.091250  0.170893  0.016178   \n",
       "3145     9.179264  0.921649  0.576089  ...  0.082404  0.183387  0.034043   \n",
       "3146     8.000504  0.958531  0.721682  ...  0.124695  0.182513  0.068966   \n",
       "3147    11.544740  0.968324  0.784108  ...  0.131566  0.191163  0.029144   \n",
       "3148     8.528681  0.947621  0.679795  ...  0.108888  0.160473  0.019512   \n",
       "3149     8.221164  0.942404  0.628992  ...  0.090445  0.182431  0.026622   \n",
       "3150     4.185207  0.967706  0.739008  ...  0.137507  0.190093  0.019116   \n",
       "3151     9.579337  0.957433  0.717683  ...  0.113148  0.187444  0.023495   \n",
       "3152     4.019385  0.949787  0.652936  ...  0.149731  0.183974  0.051948   \n",
       "3153    10.986864  0.871215  0.236684  ...  0.189614  0.163059  0.029685   \n",
       "3154     3.733815  0.919607  0.357144  ...  0.200097  0.168531  0.063241   \n",
       "3155    15.684088  0.891448  0.321169  ...  0.178573  0.155380  0.025478   \n",
       "3156     4.945634  0.884731  0.227903  ...  0.201806  0.191704  0.032720   \n",
       "3157     4.790370  0.903458  0.246953  ...  0.203627  0.146783  0.020566   \n",
       "3158     7.483019  0.898138  0.313925  ...  0.183667  0.149237  0.018648   \n",
       "3159     5.077956  0.956201  0.706861  ...  0.168794  0.182863  0.020699   \n",
       "3160     4.304354  0.962045  0.744590  ...  0.151771  0.201600  0.023426   \n",
       "3161     5.431663  0.950750  0.658558  ...  0.170656  0.198475  0.160000   \n",
       "3162     5.118927  0.948999  0.659825  ...  0.146023  0.195640  0.039506   \n",
       "3163     6.630383  0.962934  0.763182  ...  0.131884  0.182790  0.083770   \n",
       "3164     2.503954  0.960716  0.709570  ...  0.116221  0.188980  0.034409   \n",
       "3165     6.604509  0.946854  0.654196  ...  0.142056  0.209918  0.039506   \n",
       "3166     5.388298  0.950436  0.675470  ...  0.143659  0.172375  0.034483   \n",
       "3167     5.769115  0.938829  0.601529  ...  0.165509  0.185607  0.062257   \n",
       "\n",
       "        maxfun   meandom    mindom    maxdom   dfrange   modindx   label  \n",
       "0     0.275862  0.007812  0.007812  0.007812  0.000000  0.000000    male  \n",
       "1     0.250000  0.009014  0.007812  0.054688  0.046875  0.052632    male  \n",
       "2     0.271186  0.007990  0.007812  0.015625  0.007812  0.046512    male  \n",
       "3     0.250000  0.201497  0.007812  0.562500  0.554688  0.247119    male  \n",
       "4     0.266667  0.712812  0.007812  5.484375  5.476562  0.208274    male  \n",
       "5     0.253968  0.298222  0.007812  2.726562  2.718750  0.125160    male  \n",
       "6     0.266667  0.479620  0.007812  5.312500  5.304688  0.123992    male  \n",
       "7     0.144144  0.301339  0.007812  0.539062  0.531250  0.283937    male  \n",
       "8     0.250000  0.336476  0.007812  2.164062  2.156250  0.148272    male  \n",
       "9     0.262295  0.340365  0.015625  4.695312  4.679688  0.089920    male  \n",
       "10    0.117647  0.460227  0.007812  2.812500  2.804688  0.200000    male  \n",
       "11    0.262295  0.246094  0.007812  2.718750  2.710938  0.132351    male  \n",
       "12    0.213333  0.481671  0.015625  5.015625  5.000000  0.088500    male  \n",
       "13    0.275862  1.277114  0.007812  2.804688  2.796875  0.416550    male  \n",
       "14    0.275862  1.245739  0.203125  6.742188  6.539062  0.139332    male  \n",
       "15    0.246154  1.621299  0.007812  7.000000  6.992188  0.209311    male  \n",
       "16    0.275862  1.434115  0.007812  6.320312  6.312500  0.254780    male  \n",
       "17    0.262295  0.106279  0.007812  0.570312  0.562500  0.138355    male  \n",
       "18    0.231884  0.146563  0.007812  3.125000  3.117188  0.059537    male  \n",
       "19    0.210526  0.193044  0.007812  2.820312  2.812500  0.068124    male  \n",
       "20    0.200000  0.235877  0.007812  0.718750  0.710938  0.235069    male  \n",
       "21    0.275862  0.209844  0.007812  3.695312  3.687500  0.059940    male  \n",
       "22    0.197531  0.059622  0.007812  0.445312  0.437500  0.091699    male  \n",
       "23    0.192771  0.101562  0.007812  0.562500  0.554688  0.161791    male  \n",
       "24    0.275862  0.206756  0.007812  3.953125  3.945312  0.073890    male  \n",
       "25    0.253968  0.143353  0.007812  1.062500  1.054688  0.125926    male  \n",
       "26    0.271186  0.148438  0.007812  3.609375  3.601562  0.050841    male  \n",
       "27    0.225352  0.335313  0.007812  0.710938  0.703125  0.397354    male  \n",
       "28    0.262295  0.298678  0.007812  0.679688  0.671875  0.384778    male  \n",
       "29    0.177778  0.234863  0.007812  0.507812  0.500000  0.329241    male  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "3138  0.271186  0.566840  0.007812  4.273438  4.265625  0.183258  female  \n",
       "3139  0.262295  0.877604  0.007812  4.937500  4.929688  0.171708  female  \n",
       "3140  0.266667  0.614110  0.007812  4.914062  4.906250  0.090045  female  \n",
       "3141  0.271186  0.188721  0.007812  0.750000  0.742188  0.277759  female  \n",
       "3142  0.275862  0.297953  0.007812  0.859375  0.851562  0.370904  female  \n",
       "3143  0.271186  0.634014  0.015625  5.031250  5.015625  0.121246  female  \n",
       "3144  0.275862  0.767314  0.007812  5.289062  5.281250  0.187912  female  \n",
       "3145  0.275862  0.328962  0.007812  0.750000  0.742188  0.445053  female  \n",
       "3146  0.238806  0.293527  0.007812  0.851562  0.843750  0.396091  female  \n",
       "3147  0.275862  0.214725  0.007812  0.796875  0.789062  0.351645  female  \n",
       "3148  0.275862  0.497721  0.007812  2.945312  2.937500  0.236240  female  \n",
       "3149  0.258065  0.735453  0.007812  5.531250  5.523438  0.170489  female  \n",
       "3150  0.275862  0.354367  0.007812  3.117188  3.109375  0.096069  female  \n",
       "3151  0.262295  0.622489  0.007812  4.898438  4.890625  0.128717  female  \n",
       "3152  0.253968  1.361213  0.203125  6.031250  5.828125  0.365700  female  \n",
       "3153  0.258065  1.370192  0.164062  7.000000  6.835938  0.235948  female  \n",
       "3154  0.262295  0.718750  0.148438  7.000000  6.851562  0.092208  female  \n",
       "3155  0.253968  0.637921  0.148438  6.148438  6.000000  0.101291  female  \n",
       "3156  0.275862  0.593750  0.007812  5.921875  5.914062  0.124383  female  \n",
       "3157  0.262295  0.875558  0.171875  6.898438  6.726562  0.145534  female  \n",
       "3158  0.262295  0.550312  0.007812  3.421875  3.414062  0.166503  female  \n",
       "3159  0.271186  0.988281  0.007812  5.882812  5.875000  0.268617  female  \n",
       "3160  0.266667  0.766741  0.007812  4.007812  4.000000  0.192220  female  \n",
       "3161  0.253968  0.414062  0.007812  0.734375  0.726562  0.336918  female  \n",
       "3162  0.275862  0.533854  0.007812  2.992188  2.984375  0.258924  female  \n",
       "3163  0.262295  0.832899  0.007812  4.210938  4.203125  0.161929  female  \n",
       "3164  0.275862  0.909856  0.039062  3.679688  3.640625  0.277897  female  \n",
       "3165  0.275862  0.494271  0.007812  2.937500  2.929688  0.194759  female  \n",
       "3166  0.250000  0.791360  0.007812  3.593750  3.585938  0.311002  female  \n",
       "3167  0.271186  0.227022  0.007812  0.554688  0.546875  0.350000  female  \n",
       "\n",
       "[3168 rows x 21 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency describes the number of waves that pass a fixed place in a given amount of time. So if the time it takes for a wave to pass is 1/2 second, the frequency is 2 per second. If it takes 1/100 of an hour, the frequency is 100 per hour. Sound propagates as mechanical vibration waves of pressure and displacement, in air or other substances.\n",
    "\n",
    "The median is the middle number in an ordered set of data. In a frequency table, the observations are already arranged in an ascending order. If there is an even number of observations, the median will be the mean of the two central numbers.\n",
    "\n",
    "The label describes if the voice is a a male or female. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Data preparation\n",
    "When we train our model we'll use a 10-fold `KFold` \n",
    "cross-validator **with** shuffling.\n",
    "Instantiate a `KFold` class and store it in a meaningful variable.\n",
    "\n",
    "When that is done, illustrate that you indeed do get 10 \n",
    "iterations of your data by iterating over the folds and simply\n",
    "printing *the shape of* the four variables: `x_train`, `y_train`, `x_test` and\n",
    "`y_test` (see \n",
    "the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) for examples on\n",
    "how to do this).\n",
    "\n",
    "Hand in\n",
    "* the instantiation of the k-fold cross-validator\n",
    "* a loop that prints the *shape* of `x_train`, `y_train`, `x_test` and `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   0    1    2 ... 3164 3166 3167] TEST: [   8   14   18   38   41   50   51   75   81   92   94  106  112  113\n",
      "  123  134  137  138  165  182  184  192  195  204  213  217  248  251\n",
      "  253  254  258  261  267  281  294  300  313  320  321  349  351  359\n",
      "  371  374  376  403  409  432  437  441  449  458  507  511  515  523\n",
      "  546  548  559  563  567  570  594  600  606  624  629  637  643  666\n",
      "  674  686  688  700  713  720  721  732  734  739  742  744  748  755\n",
      "  775  777  791  804  812  813  815  821  836  847  872  880  892  893\n",
      "  903  915  918  936  947  955  964  969  972  973  978  990 1007 1020\n",
      " 1030 1035 1038 1070 1080 1093 1099 1102 1117 1119 1134 1166 1168 1169\n",
      " 1195 1212 1220 1223 1236 1237 1238 1245 1253 1277 1278 1282 1287 1290\n",
      " 1296 1305 1312 1314 1315 1318 1336 1339 1360 1378 1388 1392 1422 1446\n",
      " 1463 1523 1530 1533 1535 1536 1551 1566 1572 1586 1588 1607 1609 1610\n",
      " 1625 1628 1635 1653 1656 1657 1658 1661 1667 1679 1723 1726 1742 1745\n",
      " 1756 1768 1773 1777 1795 1797 1810 1828 1830 1840 1908 1914 1921 1925\n",
      " 1934 1937 1958 1969 1970 1979 1981 2016 2049 2061 2073 2075 2084 2086\n",
      " 2116 2127 2135 2146 2172 2176 2185 2186 2187 2196 2210 2213 2223 2229\n",
      " 2230 2234 2236 2238 2239 2257 2261 2262 2264 2292 2301 2308 2314 2351\n",
      " 2361 2376 2390 2424 2432 2434 2458 2474 2495 2497 2499 2505 2512 2516\n",
      " 2546 2550 2552 2558 2565 2588 2606 2607 2612 2630 2634 2640 2665 2676\n",
      " 2697 2702 2706 2707 2709 2718 2733 2739 2752 2767 2784 2815 2827 2843\n",
      " 2859 2860 2865 2867 2873 2876 2912 2915 2921 2936 2963 2980 2994 2999\n",
      " 3000 3023 3036 3038 3048 3052 3057 3058 3080 3090 3092 3097 3104 3112\n",
      " 3113 3116 3126 3142 3144 3145 3156 3159 3165]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    9,   10,\\n            ...\\n            3155, 3157, 3158, 3160, 3161, 3162, 3163, 3164, 3166, 3167],\\n           dtype='int64', length=2851)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-296b0f212f18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TRAIN:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TEST:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[0;32m-> 2934\u001b[0;31m                                                    raise_missing=True)\n\u001b[0m\u001b[1;32m   2935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[1;32m   1353\u001b[0m                           raise_missing}\n\u001b[0;32m-> 1354\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[1;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1244\u001b[0m                 raise KeyError(\n\u001b[1;32m   1245\u001b[0m                     u\"None of [{key}] are in the [{axis}]\".format(\n\u001b[0;32m-> 1246\u001b[0;31m                         key=key, axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    9,   10,\\n            ...\\n            3155, 3157, 3158, 3160, 3161, 3162, 3163, 3164, 3166, 3167],\\n           dtype='int64', length=2851)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = df.loc[:, df.columns != 'label']\n",
    "y = df[\"label\"];\n",
    "\n",
    "\n",
    "#Instanciating the k-fold cross-validator\n",
    "folder = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "\n",
    "#Loop that prints the shape\n",
    "for train_index, test_index in folder.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Part 3: Model construction\n",
    "We will use four different classification models for this task:\n",
    "1. Logistic Regression\n",
    "2. Support Vector Machine classifier\n",
    "3. Decision Tree classifier\n",
    "4. k-Nearest Neighbors classifier\n",
    "\n",
    "Instantiate the four different classifiers in *four different \n",
    "pipelines*.\n",
    "\n",
    "For now the default parameters are fine.\n",
    "\n",
    "Hand in \n",
    "* the code for constructing the four pipelines\n",
    "* one line of text per model describing how you think the classifier will perform, given the data type you are working with (voice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "p1 = make_pipeline(LogisticRegression(solver='lbfgs'))\n",
    "p2 = make_pipeline(SVC(gamma='scale'))\n",
    "p3 = make_pipeline(DecisionTreeClassifier())\n",
    "p4 = make_pipeline(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "The classificer will perform good because the output is a binary dependant variable. Which means that we have a dependant variable with two possible values; male and female. \n",
    "\n",
    "### Support Vector Machine classifier\n",
    "Bad\n",
    "\n",
    "\n",
    "### Decision Tree classifier\n",
    "Good\n",
    "\n",
    "\n",
    "### k-Nearest Neighbors classifier\n",
    "Meh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Model validation\n",
    "Now the time comes to train and validate your model.\n",
    "This training and testing **should happen for all four models**.\n",
    "The easiest way to do this is to use the `cross_val_score` \n",
    "function from `sklearn` once for all the four models.\n",
    "The code should look something like this:\n",
    "```python\n",
    "pipeline1 = ...\n",
    "pipeline2 = ...\n",
    "pipeline3 = ...\n",
    "pipeline4 = ...\n",
    "my_kfold_validator = ...\n",
    "for model in ... :\n",
    "    score = cross_val_score(model, ...)\n",
    "    print(score)\n",
    "```\n",
    "\n",
    "Hand in\n",
    "* a list per model (four lists in total) of 10 values each, showing the scores of the 10 folds,\n",
    "* at least one paragraph of text that describes what the 'score' means\n",
    "* at least one paragraph of text that describes why the scores are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bear/.pyenv/versions/3.6.8/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/bear/.pyenv/versions/3.6.8/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/bear/.pyenv/versions/3.6.8/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/bear/.pyenv/versions/3.6.8/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/bear/.pyenv/versions/3.6.8/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/bear/.pyenv/versions/3.6.8/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/bear/.pyenv/versions/3.6.8/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/bear/.pyenv/versions/3.6.8/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/bear/.pyenv/versions/3.6.8/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/bear/.pyenv/versions/3.6.8/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88958991 0.90536278 0.91167192 0.92744479 0.93059937 0.80757098\n",
      " 0.9022082  0.9022082  0.8164557  0.90506329]\n",
      "[0.66876972 0.73817035 0.6340694  0.69085174 0.68138801 0.72239748\n",
      " 0.66246057 0.69085174 0.62974684 0.6835443 ]\n",
      "[0.97160883 0.96529968 0.96214511 0.96845426 0.96845426 0.96845426\n",
      " 0.97791798 0.95899054 0.95886076 0.94936709]\n",
      "[0.71293375 0.72870662 0.74763407 0.7192429  0.7318612  0.69716088\n",
      " 0.72239748 0.72555205 0.71202532 0.72151899]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "for model in [p1, p2, p3, p4]:\n",
    "    print(cross_val_score(model, xs, ys, cv=folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "Good\n",
    "\n",
    "### Support Vector Machine classifier\n",
    "Bad\n",
    "\n",
    "\n",
    "### Decision Tree classifier\n",
    "Good\n",
    "\n",
    "\n",
    "### k-Nearest Neighbors classifier\n",
    "Meh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Model optimisation: scaling\n",
    "On the website of the [Gender Recognition by Voice](https://www.kaggle.com/primaryobjects/voicegender) dataset, they say\n",
    "we can do better. So let's try!\n",
    "\n",
    "One thing that's very easy to do is to use a \n",
    "[StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html).\n",
    "It's particularly easy, because it fits right into your existing\n",
    "pipelines. So simply add four (separate!) instances of the\n",
    "`StandardScaler` to the pipelines, one for each pipeline.\n",
    "\n",
    "Now repeat the above validation code, where you run the \n",
    "`cross_val_score` for *each* of the four pipelines. But this \n",
    "time the `StandardScaler` is included in the pipeline.\n",
    "\n",
    "Hand in\n",
    "* the code for your new pipelines that includes the `StandardScaler`)\n",
    "* at least one line of text that describes what scaling actually is\n",
    "* the **mean** of the 10 scores of the four models (this time it's only **one** number per model\n",
    "* at least two lines of text describing which model performed well, and whether this aligned with your expectation from part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = make_pipeline(StandardScaler(), LogisticRegression(solver='lbfgs'))\n",
    "p2 = make_pipeline(StandardScaler(), SVC(gamma='scale'))\n",
    "p3 = make_pipeline(StandardScaler(), DecisionTreeClassifier())\n",
    "p4 = make_pipeline(StandardScaler(),KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9734866030427665\n",
      "0.9820089446152618\n",
      "0.9614912350756699\n"
     ]
    }
   ],
   "source": [
    "for model in [p1, p2, p3,p4]: ##SpECiAl coDe\n",
    "    print(cross_val_score(model, xs, ys, cv=folder).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9741161616161617"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "p5 = make_pipeline(StandardScaler(), \n",
    "                   GridSearchCV(LogisticRegression(solver='lbfgs'), param_grid={'C': np.arange(0.0001, 2, 0.05)}, cv=10))\n",
    "p5.fit(xs, ys)\n",
    "p5.score(xs,ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Manual Hyperparameter Tuning\n",
    "\n",
    "For the fourth classifier in this project -- namely kNN -- conduct a manual search for the best value of $k$ (the hyperparameter n_neighbors), that yields the highest score.\n",
    "\n",
    "That means:\n",
    "\n",
    "  1. choosing a value (positive integer >= 1), \n",
    "  2. putting it into the model, \n",
    "  3. (re-)training the kNN model, and \n",
    "  4. calculating the score. \n",
    "  5. Then try 1)-4) all over again. \n",
    "\n",
    "Do these steps at least 10 times to find a good value of the hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
